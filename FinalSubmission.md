1. I will have finished polishing the pipeline by making sure my midi files read and write fast enough to the client side and that tracks can play at the same time with quantization and there is no odd state that can be reached by turning on and off tracks randomly.

2. Since I decided not to use the server to complete the project, I stored all the notes data in redux. Notes that are recorded are just stored in an array of notes arrays so that even chords will be recorded. I chose this way of doing what I wanted since this change was more feasible. I did not have to figure out how to parse a midi file for playback and writing to a MIDI file wasn't the only way to record audio when you can just invent a data structure for recording notes instead. Furthermore, having it in redux makes it easy to offload to a server when there are many notes being recorded, and then the server and client could talk over sockets so that playback is streaming in realtime no problem. I do want to look into the web audio api to see if you can in fact convert a string into a midi file and play it back over a stream. The API I had thought was going to be able to do this, ScribbleTune, seems to just write the whole file at once, which makes it difficult to stream in real time.

3. Looking into the future, I want to record which sound the user recorded the track in. I also want to add effects and filters to different instrument sounds so that you can create preset instruments. I also want to add the merge operation between tracks, so that you can blend together rhythms but choose one of the sounds for that rhythm to play with.

4. Screenshots in finalsubmission folder.